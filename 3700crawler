#!/usr/bin/env python3

import argparse, socket, ssl
from posixpath import split
from ast import parse

from html.parser import HTMLParser
from urllib.parse import urlparse


DEFAULT_SERVER = "project5.3700.network"
DEFAULT_LOGIN = "/accounts/login/"
DEFAULT_PORT = 443

# Nick's Login: 
# username: coury.ni
# password: 001477153

visited_pages = [] # Represents pages that we have visited
fronteir = [] # Represents pages that we are going to visit
flags = [] # Holds all discovered flags 
middleware_token = "" # Used for the login 

class MyHTMLParser(HTMLParser):
    # This gets all the links we need to process and adds them to pages_to_visit iff they haven't been visited
    #  tag a references a link -> href= LINK
    #  <a href= LINK>TEXT</a>
    def handle_starttag(self, tag, attrs):
        # We only care about links to other pages 
        global middleware_token
        if (tag == "a"):
            # Possibly leave this out later when we test
            for attr in attrs:
            # attr -> (name, value) -> (href, link)
                if (attr[0] == "href" and attr[1] not in fronteir and attr[1] not in visited_pages):
                    fronteir.append(attr[1])

        # Example tag for middleware token:       
        # <input type="hidden" name="csrfmiddlewaretoken" value="sP02rxK0K6gHIn4j8X2gmE77wa10WJPJjctTWZ65Xq79I6yxfSLO0kW95zvjykT8">
        
        # If we encounter the middleware, we know that the value is stored in the 3rd attribute
        #  Save it off
        elif(tag == "input"):
            for attr in attrs:
                if(attr[1] == "csrfmiddlewaretoken"):
                    middleware_token = attrs[2][1]
                    break


class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password  
        self.html_parser = MyHTMLParser()

        self.cookie = ""

    def get_cookie(self):
        return     

    # Returns a dictionary contatiing important elements of the HTTP Response
    #  Status -> Always returns a status code
    #  csurf -> Returns if a token is present
    #  sessionid -> Returns if a session id is present
    def parse_http(self, data):
        split_data = data.split("\n")
        data_dict = {}

        dictionary = {}
        i = 0
        for line in split_data:
            if i != 0: 
                new_split = line.split(": ")
                # print("key: ", new_split[0])
                # print("value: ", new_split[1])
                dictionary[new_split[0]] = new_split[1]
            i += 1    
        print("DICTIONARY\n")
        print(dictionary)
        print("++++++++++")
        # for line in split_data :
        #     # Handle Status Codes
        #     if "HTTP/1.1 " in line :
        #         if "200" in line : 
        #             data_dict["status"] = 200
        #         elif "302" in line :
        #             data_dict["status"] = 302
        #         elif "403" in line or "404" in line :
        #             data_dict["status"] = 403 
        #         elif "500" in line :
        #             data_dict["status"] = 500
        #         else:
        #             raise Exception("MESSED UP STATUS CODE")
        #     # Handle Cookies
        #     elif "Set-Cookie: " in line:
                
        
        return

    def get_req(self, sock, host, path):        
        # Add path to the visited_pages list
        visited_pages.append(path)
        
        # Checking if this is the root of the Host
        if(path == " "):
            path = "/" 

        # netloc is the root url  
        # original URL: "scheme://netloc/path;parameters?query#fragment"
        print("HOST: %s\n" % host)

        #self.get_cookie()
        message = "GET %s HTTP/1.0\r\nHost: %s\r\n%s\r\n" % (path, host, self.cookie)
        print("THE GET MSG: %s" % message)

        # Sending the GET request over the previously wrapped socket 
        sock.send(message.encode())
        # Recieve a Message
        data = sock.recv(100000)
        
        # Split here into HTTP and HTML responses
        split_response = data.split(b"\r\n\r\n\n\n\n")
        http_response = split_response[0].decode()
        html_response = split_response[1].decode()
        #print("HTTP RESPONSE: \n", http_response)
        #print("HTML RESPONSE: \n", html_response)

        # Feed the data to our parsers
        self.html_parser.feed(html_response)
        self.parse_http(http_response)
        
        print("UPDATED MIDDLEWARE TOKEN: ", middleware_token)
        print("UPDATED FRONTEIR ", fronteir)

        return data
# \r\n\r\n
# parsed_data[0] = HTTP -> First line HTTP Code (200) , Everything else is the fields -> Dictionary
# paradasdasdsaas[1] = HTML
    

    def login(self, sock, username, password):
        on_login_page = False
        while not on_login_page:
            loginPage = self.get_req(sock, DEFAULT_SERVER, DEFAULT_LOGIN)
            on_login_page = True
            # add a helper that takes in a get request and returns a dictionary 
            # if loginPage['Status'] == "200":
            #     on_login_page = True

        # POST path_from_host HTTTP/1.1
        # Host: DEFAULT_URL
        # Cookie: COOKIE
        # Content Length: (Size of the arugments including \r\n)
        # username=___&password=___&crfmiddlewaretocken=___
        # Content-Type: application/x-www-form-urlencoded

        # login = "POST %s HTTP/1.0\r\n" % DEFAULT_LOGIN
        # header_list = ['Content-Type: application/x-www-form-urlencoded', 'Host: ' + DEFAULT_SERVER] 
        # content = "username={username}&password={password}&crfmifflewaretoken={token}&next=%2Ffakebook%2F\r\n"
        # # Connects to the server @ port 
        # sock.connect(DEFAULT_LOGIN)
    
    def run(self):      
        # Init the socket and wrap in SSL 
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        context = ssl.SSLContext()
        mysocket = context.wrap_socket(mysocket, server_hostname=self.server)

        mysocket.connect((self.server, self.port))

        self.login(mysocket, "coury.ni", "001477153")

        # Start the crawl


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
